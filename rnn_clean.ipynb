{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> FLOW<h2>\n",
    "<h3>> Certain amount of time is set to give use some time to get ready</h3>\n",
    "<h3>> the trainer will then assume the pose that leads to the first part of the exercise</h3>\n",
    "<h3>> an indicator will prompt the user to perform the exercise</h3>\n",
    "<h3>> the user will have to stop in between exercise</h3>\n",
    "\n",
    "    example:    \n",
    "        push-up:    \n",
    "            1) Starting Position:\n",
    "            2) Push-Up Descent:\n",
    "            3) Push-Up Ascent:  \n",
    "            4) Stop momentarily, then it'll prompt to do it again   \n",
    "\n",
    "<h3>> every start of the exercise will be recorded unto a txt file for the landmark coordinates</h3>\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA COLLECTING\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from IPython.display import clear_output\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# cap = cv2.VideoCapture(\"vid4.mp4\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# parameters:\n",
    "# ================================================================================================================================\n",
    "# timer to ready before posing/getting ready for the excercise\n",
    "set_timer_start = 50\n",
    "# ================================================================================================================================\n",
    "# range of how much change will it be considered a movement\n",
    "# lower -> small movement and jittery flaw of mediapipe will be detected\n",
    "# higher -> it wont detect immediately important frames\n",
    "# 0-1\n",
    "change_range = .03\n",
    "# ================================================================================================================================\n",
    "# a counter for the amount of time for the wait time before performing the exercise again\n",
    "between_exercise_ctr = 6\n",
    "\n",
    "\n",
    "\n",
    "isInitiated = False\n",
    "exercise_exectuted_ctr=0\n",
    "prev_x = 0\n",
    "prev_y = 0\n",
    "no_movement_ctr = 0\n",
    "movement_boolean = False\n",
    "timer = 0\n",
    "\n",
    "prev_array = []\n",
    "\n",
    "for x in range(33):\n",
    "    prev_array.append([0, 0])\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(image_rgb)\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    timer += 1 \n",
    "    landmark_all_present = False\n",
    "\n",
    "    if timer == set_timer_start:\n",
    "        file = open('base.txt', 'w')\n",
    "        if isInitiated==False:\n",
    "            file.write(\"START\")\n",
    "            file.write('\\n')\n",
    "        isInitiated = True\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        ctr_check=0\n",
    "\n",
    "        for idx, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "            if idx == 32:\n",
    "                landmark_all_present = \"Landmarks -> ALL PRESENT\"\n",
    "            else:\n",
    "                landmark_all_present = \"Landmarks -> SOME ARE MISSING\"\n",
    "\n",
    "            x = landmark.x\n",
    "            y = landmark.y\n",
    "\n",
    "#checks if no movement is detected-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "            if x >= (prev_array[idx][0] - change_range) and y <= (prev_array[idx][1] + change_range) and isInitiated:   \n",
    "                print(idx,\")\",x,\"---\",prev_array[idx][0],'---> NO MOVEMENT')\n",
    "                ctr_check+=1          \n",
    "                \n",
    "            else:\n",
    "                print(idx,\")\",x,\"---\",prev_array[idx][0],'--->YES MOVEMENT',)\n",
    "                movement_boolean = True\n",
    "                no_movement_ctr = 0\n",
    "\n",
    "            if ctr_check==32:\n",
    "                no_movement_ctr += 1 \n",
    "\n",
    "            if no_movement_ctr>=25:\n",
    "                movement_boolean=False\n",
    "            prev_array[idx] = [x, y]\n",
    "        print('counter->',no_movement_ctr)\n",
    "        print(movement_boolean)\n",
    "\n",
    "#if movement is detected then it will record the coordinates into a text file-----------------------------------------------------------------------------------------------------\n",
    "        if movement_boolean:\n",
    "            text = \"MOVEMENT\"      \n",
    "            if timer >= set_timer_start and file is not None:\n",
    "                for landmark in prev_array:\n",
    "                    # file.write(\"<\")\n",
    "                    file.write(\"|\")\n",
    "                    file.write(str(landmark[0]))\n",
    "                    file.write(\"|\")\n",
    "                    file.write(str(landmark[1]))\n",
    "                    # file.write(\">\")\n",
    "                    # file.write(\"|\")\n",
    "                file.write('\\n')\n",
    "\n",
    "        if no_movement_ctr >= 5:    \n",
    "            movement_boolean = False\n",
    "            text = \"NO MOVEMENT!\"\n",
    "\n",
    "        if no_movement_ctr == between_exercise_ctr:\n",
    "            exercise_exectuted_ctr+=1\n",
    "            file.write(\"END\")  \n",
    "            file.write('\\n')\n",
    "            file.write('\\n')\n",
    "            file.write(\"START\")\n",
    "            file.write('\\n')\n",
    "\n",
    "\n",
    "\n",
    "        if timer >= set_timer_start and no_movement_ctr >=between_exercise_ctr:\n",
    "            cv2.putText(frame, \"PERFORM THE EXERCISE\", (180, 460), cv2.FONT_HERSHEY_SIMPLEX, .5, (0, 0, 255), 2)\n",
    "# -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#Outputing important informations-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        cv2.putText(frame, str(movement_boolean), (20, 20), cv2.FONT_HERSHEY_SIMPLEX, .5, (0, 0, 255), 1)\n",
    "        cv2.putText(frame, f\"no_movement_ctr-> {no_movement_ctr}\", (20, 37), cv2.FONT_HERSHEY_SIMPLEX, .5, (0, 0, 255), 1)\n",
    "        cv2.putText(frame, str(landmark_all_present), (20, 54), cv2.FONT_HERSHEY_SIMPLEX, .5, (0, 0, 255), 1)\n",
    "        cv2.putText(frame, f\"timer-> {timer}\", (20, 73), cv2.FONT_HERSHEY_SIMPLEX, .5, (0, 0, 255), 1)\n",
    "        cv2.putText(frame, f\"exercise exectuted-> {exercise_exectuted_ctr}\", (20, 92), cv2.FONT_HERSHEY_SIMPLEX, .5, (0, 0, 255), 1)\n",
    "# -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        if timer < set_timer_start:\n",
    "            cv2.putText(frame, \"PREPARE YOUR STARTING POSE\", (180, 460), cv2.FONT_HERSHEY_SIMPLEX, .5, (0, 0, 255), 2)\n",
    "            \n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "            connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)\n",
    "        )\n",
    "\n",
    "    cv2.imshow('MediaPipe Pose', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "if file is not None:\n",
    "    file.close()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def txt_pre_process(txt_file,label,simplify=False,simplify_level=4 ):\n",
    "    label_array = []\n",
    "    temp_feature_data = []\n",
    "    temp_sequence_data = []\n",
    "    batch_data = []\n",
    "\n",
    "    with open(str(txt_file), 'r') as file:\n",
    "\n",
    "        for line in file:\n",
    "            values = line.strip().split('|')        \n",
    "\n",
    "            temp_feature_data = []\n",
    "\n",
    "            for value in values:            \n",
    "                float_value = str(value)\n",
    "\n",
    "                #FIRST PART OF THE SEQUENCE \n",
    "                if float_value == 'START':   \n",
    "                    temp_sequence_data=[]\n",
    "                                        \n",
    "                elif float_value == 'END':              \n",
    "                    batch_data.append(temp_sequence_data)\n",
    "                    label_array.append(label)\n",
    "\n",
    "            \n",
    "                elif float_value != '' and float_value != 'START': \n",
    "                    if simplify:    \n",
    "                        float_value = round(float(value),simplify_level)\n",
    "                    else:\n",
    "                        float_value = float(value)\n",
    "                    temp_feature_data.append(float_value)\n",
    "\n",
    "            if temp_feature_data!=[]:\n",
    "                temp_sequence_data.append(temp_feature_data)\n",
    "\n",
    "    label_array = np.array(label_array)\n",
    "    return [batch_data,label_array]\n",
    "\n",
    "#--------------------------------------------------------------------------- padding --------------------------------------------------------------------------------\n",
    "# padding can be improved probably...by using sequence \n",
    "# minor issue:\n",
    "# > is whether sequences had exceeded the intended number of sequences but is still right (it was performed right but slower(by an acceptable margin)) - not resolved\n",
    "#    = temporary fix was just to truncate everything if it had exceeded the intended number of sequence for the sake of running it for now\n",
    "\n",
    "\n",
    "def padding(pre_processed_input,optional_maxLength=0): \n",
    "    padded_sequences = []\n",
    "    if optional_maxLength != 0:\n",
    "        max_length = optional_maxLength\n",
    "    else:\n",
    "        max_length = max(len(sequence) for sequence in pre_processed_input)\n",
    "    \n",
    "    for sequence in pre_processed_input:        \n",
    "        padding_length = max_length - len(sequence)\n",
    "        if padding_length >= 0:\n",
    "            padded_sequence = np.pad(sequence, ((0, padding_length), (0, 0)), mode='constant')\n",
    "            \n",
    "        else:\n",
    "            padded_sequence = sequence[:max_length]\n",
    "        padded_sequences.append(padded_sequence)\n",
    "    padded_sequences = np.array(padded_sequences)\n",
    "\n",
    "    return padded_sequences\n",
    "\n",
    "#--------------------------------------------------------------------------- padding --------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def concatenate_randomize_batches(base_input,base_label,concat_input,concat_label):\n",
    "    combined_inputs = np.concatenate((base_input,concat_input), axis = 0)\n",
    "    combined_label = np.concatenate((base_label,concat_label), axis = 0)\n",
    "    indices = np.random.permutation(len(combined_inputs))\n",
    "    randomized_inputs = combined_inputs[indices]\n",
    "    randomized_label = combined_label[indices]\n",
    "    return [randomized_inputs,randomized_label]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------checking:-------------------\n",
      "base_input-> (60, 31, 66)\n",
      "concat_input-> (44, 31, 66)\n",
      "successfully merged and randomized(input) -> (104, 31, 66)\n",
      "successfully merged and randomized(label) -> (104,)\n"
     ]
    }
   ],
   "source": [
    "temp_correct = txt_pre_process('base(correct_execution).txt',1,True,4)\n",
    "temp_wrong = txt_pre_process('base(wrong_execution).txt',0,True,4)\n",
    "\n",
    "base_input = padding(temp_correct[0])\n",
    "concat_input = padding(temp_wrong[0],31)\n",
    "\n",
    "base_label = temp_correct[1]\n",
    "concat_label = temp_wrong[1]\n",
    "\n",
    "# optional if labels were not initially assigned\n",
    "# correct_labels = np.ones(len(base_input))  # Assign label 1 to correct inputs\n",
    "# wrong_labels = np.zeros(len(concat_input))  # Assign label 0 to wrong inputs\n",
    "\n",
    "rand_batches=concatenate_randomize_batches(base_input,base_label,concat_input,concat_label)\n",
    "\n",
    "print(\"-------------------checking:-------------------\")\n",
    "print(\"base_input->\",base_input.shape)\n",
    "print(\"concat_input->\",concat_input.shape)\n",
    "print(\"successfully merged and randomized(input) ->\",rand_batches[0].shape)\n",
    "print(\"successfully merged and randomized(label) ->\",rand_batches[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_sequences shape: (60, 31, 66)\n",
      "label shape: (60,)\n"
     ]
    }
   ],
   "source": [
    "temp = txt_pre_process('base(correct_execution).txt',1)\n",
    "inputs = padding(temp[0])\n",
    "label = temp[1]\n",
    "\n",
    "print(\"padded_sequences shape:\", inputs.shape)\n",
    "print(\"label shape:\", label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 31, 66)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(base_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4153, 0.0776, 0.4178, ..., 0.8023, 0.356 , 0.7986],\n",
       "       [0.4192, 0.0777, 0.4205, ..., 0.8032, 0.3533, 0.7988],\n",
       "       [0.4213, 0.0777, 0.422 , ..., 0.804 , 0.349 , 0.799 ],\n",
       "       ...,\n",
       "       [0.4228, 0.0771, 0.4256, ..., 0.8104, 0.356 , 0.8038],\n",
       "       [0.4228, 0.0771, 0.4254, ..., 0.8098, 0.3559, 0.804 ],\n",
       "       [0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = [1] * len(base_input)\n",
    "test_label = np.ones(len(test_label)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(rand_batches[0], rand_batches[1], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(31, 66)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu')) \n",
    "model.add(LSTM(64, return_sequences=False, activation='relu')) \n",
    "model.add(Dense(64, activation='relu')) \n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer = 'Adam' , loss = 'binary_crossentropy', metrics=['accuracy', 'binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "# version 2\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', dropout=0.2, recurrent_dropout=0.2, input_shape=(31, 66)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu')) \n",
    "model.add(LSTM(64, return_sequences=False, activation='relu')) \n",
    "model.add(Dense(64, activation='relu')) \n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer = 'Adam' , loss = 'binary_crossentropy', metrics=['accuracy', 'binary_accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 31, 66)\n",
      "(104,)\n"
     ]
    }
   ],
   "source": [
    "print(rand_batches[0].shape)\n",
    "print(rand_batches[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 31, 66)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "print(base_input.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(base_input,test_label,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 3s 944ms/step - loss: 1.1314 - accuracy: 0.5301 - binary_accuracy: 0.5301 - val_loss: 0.9208 - val_accuracy: 0.3333 - val_binary_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 3s 885ms/step - loss: 0.8739 - accuracy: 0.4458 - binary_accuracy: 0.4458 - val_loss: 0.8130 - val_accuracy: 0.3333 - val_binary_accuracy: 0.3333\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 2s 766ms/step - loss: 0.7770 - accuracy: 0.4458 - binary_accuracy: 0.4458 - val_loss: 0.7723 - val_accuracy: 0.3333 - val_binary_accuracy: 0.3333\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 2s 875ms/step - loss: 0.7395 - accuracy: 0.4458 - binary_accuracy: 0.4458 - val_loss: 0.7418 - val_accuracy: 0.3333 - val_binary_accuracy: 0.3333\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 2s 817ms/step - loss: 0.7147 - accuracy: 0.4458 - binary_accuracy: 0.4458 - val_loss: 0.7183 - val_accuracy: 0.3333 - val_binary_accuracy: 0.3333\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6948 - accuracy: 0.4458 - binary_accuracy: 0.4458 - val_loss: 0.7092 - val_accuracy: 0.3333 - val_binary_accuracy: 0.3333\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6785 - accuracy: 0.4458 - binary_accuracy: 0.4458 - val_loss: 0.6970 - val_accuracy: 0.3333 - val_binary_accuracy: 0.3333\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 3s 835ms/step - loss: 0.6617 - accuracy: 0.4699 - binary_accuracy: 0.4699 - val_loss: 0.6603 - val_accuracy: 0.5238 - val_binary_accuracy: 0.5238\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 3s 920ms/step - loss: 0.6435 - accuracy: 0.8072 - binary_accuracy: 0.8072 - val_loss: 0.6323 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 2s 801ms/step - loss: 0.6268 - accuracy: 0.8675 - binary_accuracy: 0.8675 - val_loss: 0.6258 - val_accuracy: 0.8571 - val_binary_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 3s 918ms/step - loss: 0.6064 - accuracy: 0.8916 - binary_accuracy: 0.8916 - val_loss: 0.5993 - val_accuracy: 0.9048 - val_binary_accuracy: 0.9048\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 2s 786ms/step - loss: 0.5777 - accuracy: 0.8916 - binary_accuracy: 0.8916 - val_loss: 0.5519 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 2s 706ms/step - loss: 0.5416 - accuracy: 0.9277 - binary_accuracy: 0.9277 - val_loss: 0.5152 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 2s 721ms/step - loss: 0.5026 - accuracy: 0.9036 - binary_accuracy: 0.9036 - val_loss: 0.4421 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 2s 814ms/step - loss: 0.4119 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.3162 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 3s 866ms/step - loss: 0.3111 - accuracy: 0.9157 - binary_accuracy: 0.9157 - val_loss: 0.1064 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 3s 865ms/step - loss: 1.1225 - accuracy: 0.6627 - binary_accuracy: 0.6627 - val_loss: 0.5179 - val_accuracy: 0.7143 - val_binary_accuracy: 0.7143\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 2s 812ms/step - loss: 0.3733 - accuracy: 0.8916 - binary_accuracy: 0.8916 - val_loss: 0.3827 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 2s 832ms/step - loss: 0.4616 - accuracy: 0.8795 - binary_accuracy: 0.8795 - val_loss: 0.4360 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 2s 827ms/step - loss: 0.5478 - accuracy: 0.7831 - binary_accuracy: 0.7831 - val_loss: 0.4459 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 2s 840ms/step - loss: 0.5481 - accuracy: 0.7590 - binary_accuracy: 0.7590 - val_loss: 0.4519 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 2s 832ms/step - loss: 0.4926 - accuracy: 0.8675 - binary_accuracy: 0.8675 - val_loss: 0.5125 - val_accuracy: 0.8571 - val_binary_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 2s 836ms/step - loss: 0.4960 - accuracy: 0.9036 - binary_accuracy: 0.9036 - val_loss: 0.5766 - val_accuracy: 0.7143 - val_binary_accuracy: 0.7143\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 2s 828ms/step - loss: 0.4888 - accuracy: 0.8675 - binary_accuracy: 0.8675 - val_loss: 0.5975 - val_accuracy: 0.6667 - val_binary_accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 3s 852ms/step - loss: 0.4808 - accuracy: 0.8675 - binary_accuracy: 0.8675 - val_loss: 0.5444 - val_accuracy: 0.7619 - val_binary_accuracy: 0.7619\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 2s 763ms/step - loss: 0.4626 - accuracy: 0.8675 - binary_accuracy: 0.8675 - val_loss: 0.4633 - val_accuracy: 0.9048 - val_binary_accuracy: 0.9048\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 2s 834ms/step - loss: 0.4413 - accuracy: 0.9036 - binary_accuracy: 0.9036 - val_loss: 0.4053 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 2s 839ms/step - loss: 0.4384 - accuracy: 0.8916 - binary_accuracy: 0.8916 - val_loss: 0.3605 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 2s 841ms/step - loss: 0.4160 - accuracy: 0.9157 - binary_accuracy: 0.9157 - val_loss: 0.3337 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 3s 849ms/step - loss: 0.4123 - accuracy: 0.8675 - binary_accuracy: 0.8675 - val_loss: 0.3317 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 3s 835ms/step - loss: 0.3544 - accuracy: 0.9277 - binary_accuracy: 0.9277 - val_loss: 0.3333 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 2s 860ms/step - loss: 0.3291 - accuracy: 0.9398 - binary_accuracy: 0.9398 - val_loss: 0.2934 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 2s 825ms/step - loss: 0.3255 - accuracy: 0.9157 - binary_accuracy: 0.9157 - val_loss: 0.2258 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 2s 810ms/step - loss: 0.2894 - accuracy: 0.9398 - binary_accuracy: 0.9398 - val_loss: 0.1545 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 2s 792ms/step - loss: 0.2508 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.0610 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 2s 762ms/step - loss: 0.2808 - accuracy: 0.9036 - binary_accuracy: 0.9036 - val_loss: 0.1377 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 2s 753ms/step - loss: 0.2899 - accuracy: 0.9036 - binary_accuracy: 0.9036 - val_loss: 0.0441 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 2s 831ms/step - loss: 0.2868 - accuracy: 0.9157 - binary_accuracy: 0.9157 - val_loss: 0.0770 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 2s 791ms/step - loss: 0.2200 - accuracy: 0.9157 - binary_accuracy: 0.9157 - val_loss: 0.1292 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 2s 760ms/step - loss: 0.2158 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.1508 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 2s 737ms/step - loss: 0.2069 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.1123 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 3s 837ms/step - loss: 0.1824 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.0607 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 2s 834ms/step - loss: 0.2290 - accuracy: 0.9398 - binary_accuracy: 0.9398 - val_loss: 0.0427 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 2s 847ms/step - loss: 0.2327 - accuracy: 0.9277 - binary_accuracy: 0.9277 - val_loss: 0.2434 - val_accuracy: 0.9048 - val_binary_accuracy: 0.9048\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 2s 794ms/step - loss: 0.2912 - accuracy: 0.8795 - binary_accuracy: 0.8795 - val_loss: 0.0692 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 2s 808ms/step - loss: 0.2058 - accuracy: 0.9398 - binary_accuracy: 0.9398 - val_loss: 0.0550 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 2s 848ms/step - loss: 0.1539 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.0522 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 2s 844ms/step - loss: 0.1603 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.0460 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 2s 799ms/step - loss: 0.1347 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.0404 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 2s 824ms/step - loss: 0.1342 - accuracy: 0.9398 - binary_accuracy: 0.9398 - val_loss: 0.0261 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 2s 756ms/step - loss: 0.0904 - accuracy: 0.9759 - binary_accuracy: 0.9759 - val_loss: 0.2248 - val_accuracy: 0.9048 - val_binary_accuracy: 0.9048\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 2s 799ms/step - loss: 0.3495 - accuracy: 0.8554 - binary_accuracy: 0.8554 - val_loss: 0.0322 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 2s 827ms/step - loss: 0.1594 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.0664 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 2s 754ms/step - loss: 0.2489 - accuracy: 0.9036 - binary_accuracy: 0.9036 - val_loss: 0.1370 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 2s 740ms/step - loss: 0.2387 - accuracy: 0.9157 - binary_accuracy: 0.9157 - val_loss: 0.2020 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 2s 795ms/step - loss: 0.2953 - accuracy: 0.8916 - binary_accuracy: 0.8916 - val_loss: 0.1614 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 2s 813ms/step - loss: 0.1971 - accuracy: 0.9398 - binary_accuracy: 0.9398 - val_loss: 0.0901 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 2s 756ms/step - loss: 0.1856 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.0754 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 2s 775ms/step - loss: 0.2139 - accuracy: 0.9398 - binary_accuracy: 0.9398 - val_loss: 0.0657 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 2s 841ms/step - loss: 0.1521 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.0970 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 2s 831ms/step - loss: 0.2299 - accuracy: 0.9157 - binary_accuracy: 0.9157 - val_loss: 0.0494 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 2s 841ms/step - loss: 0.1466 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.0347 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 2s 817ms/step - loss: 0.1984 - accuracy: 0.9398 - binary_accuracy: 0.9398 - val_loss: 0.0429 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 2s 771ms/step - loss: 0.2133 - accuracy: 0.9036 - binary_accuracy: 0.9036 - val_loss: 0.0928 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 2s 836ms/step - loss: 0.1827 - accuracy: 0.9398 - binary_accuracy: 0.9398 - val_loss: 0.0524 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 2s 841ms/step - loss: 0.1710 - accuracy: 0.9398 - binary_accuracy: 0.9398 - val_loss: 0.0474 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 2s 825ms/step - loss: 0.2133 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.0570 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 2s 772ms/step - loss: 0.1297 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.0686 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 2s 830ms/step - loss: 0.1339 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.0460 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 2s 759ms/step - loss: 0.1270 - accuracy: 0.9759 - binary_accuracy: 0.9759 - val_loss: 0.0336 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 2s 829ms/step - loss: 0.1387 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.0501 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 2s 770ms/step - loss: 0.1173 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.0393 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 2s 771ms/step - loss: 0.1522 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.0206 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 2s 840ms/step - loss: 0.1614 - accuracy: 0.9036 - binary_accuracy: 0.9036 - val_loss: 0.0342 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 2s 757ms/step - loss: 0.2190 - accuracy: 0.9157 - binary_accuracy: 0.9157 - val_loss: 0.0309 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 2s 852ms/step - loss: 0.1120 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.0574 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 2s 839ms/step - loss: 0.1390 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.0420 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 2s 825ms/step - loss: 0.1400 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.0385 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 2s 818ms/step - loss: 0.1176 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.0712 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 2s 805ms/step - loss: 0.1511 - accuracy: 0.9398 - binary_accuracy: 0.9398 - val_loss: 0.1229 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 2s 786ms/step - loss: 0.1005 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.0425 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 2s 792ms/step - loss: 0.1195 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.0246 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 2s 781ms/step - loss: 0.2595 - accuracy: 0.9398 - binary_accuracy: 0.9398 - val_loss: 0.2656 - val_accuracy: 0.8571 - val_binary_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 2s 759ms/step - loss: 0.2632 - accuracy: 0.9157 - binary_accuracy: 0.9157 - val_loss: 0.2909 - val_accuracy: 0.8571 - val_binary_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 2s 835ms/step - loss: 0.1995 - accuracy: 0.9398 - binary_accuracy: 0.9398 - val_loss: 0.1207 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 2s 844ms/step - loss: 0.2243 - accuracy: 0.9277 - binary_accuracy: 0.9277 - val_loss: 0.1138 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 2s 835ms/step - loss: 0.2217 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.1306 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 2s 771ms/step - loss: 0.1632 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.1428 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 2s 764ms/step - loss: 0.1689 - accuracy: 0.9518 - binary_accuracy: 0.9518 - val_loss: 0.1168 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 2s 763ms/step - loss: 0.1580 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.0800 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 2s 812ms/step - loss: 0.1233 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.0493 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 2s 820ms/step - loss: 0.1270 - accuracy: 0.9759 - binary_accuracy: 0.9759 - val_loss: 0.0318 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 2s 806ms/step - loss: 0.1620 - accuracy: 0.9277 - binary_accuracy: 0.9277 - val_loss: 0.0636 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 2s 852ms/step - loss: 0.1184 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.1156 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 2s 782ms/step - loss: 0.0878 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.0114 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 2s 758ms/step - loss: 0.1536 - accuracy: 0.9277 - binary_accuracy: 0.9277 - val_loss: 0.0108 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 2s 747ms/step - loss: 0.0707 - accuracy: 0.9759 - binary_accuracy: 0.9759 - val_loss: 0.0241 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 2s 773ms/step - loss: 0.1103 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.0125 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 2s 744ms/step - loss: 0.0718 - accuracy: 0.9639 - binary_accuracy: 0.9639 - val_loss: 0.0123 - val_accuracy: 1.0000 - val_binary_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 3s 858ms/step - loss: 0.1913 - accuracy: 0.9277 - binary_accuracy: 0.9277 - val_loss: 0.1072 - val_accuracy: 0.9524 - val_binary_accuracy: 0.9524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f56d1b1b80>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(rand_batches[0],rand_batches[1],epochs=100)\n",
    "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 96ms/step\n",
      "0.024964636022394352\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pred = model.predict(concat_input)\n",
    "temp = np.sum(pred) / len(pred)\n",
    "print(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 31, 132)          70224     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 31, 132)          105072    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 31, 132)          105072    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 31, 132)          105072    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 132)              105072    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 132)               17556     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 133       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 508,201\n",
      "Trainable params: 508,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train shape: (88, 31, 66)\n",
      "y_train shape: (88,)\n",
      "X_test shape: (16, 31, 66)\n",
      "y_test shape: (16,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\mediapipe\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, LSTM, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import keras\n",
    "\n",
    "initial_input = rand_batches\n",
    "\n",
    "max_length = len(initial_input[0][0])\n",
    "# input_test = inputs\n",
    "# label_test = label\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(keras.Input(shape=(max_length, 66))) # seq_length, input_size\n",
    "\n",
    "model.add(Bidirectional(LSTM(66, return_sequences=True, activation='relu'))) # N, 128\n",
    "model.add(Bidirectional(LSTM(66, return_sequences=True, activation='relu')) )\n",
    "model.add(Bidirectional(LSTM(66, return_sequences=True, activation='relu')) )\n",
    "model.add(Bidirectional(LSTM(66, return_sequences=True, activation='relu')) )\n",
    "model.add(Bidirectional(LSTM(66, activation='relu'))) # N, 128\n",
    "model.add(Dense(132,activation='softmax'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "optim = keras.optimizers.Adam(lr=0.005)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(initial_input[0], initial_input[1], test_size=0.15, random_state=42)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.6931 - accuracy: 0.5909 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6920 - accuracy: 0.5909 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6908 - accuracy: 0.5909 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6873 - accuracy: 0.5909 - val_loss: 0.6846 - val_accuracy: 0.5625\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6816 - accuracy: 0.5795 - val_loss: 0.6856 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6773 - accuracy: 0.5795 - val_loss: 0.7102 - val_accuracy: 0.4375\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6927 - accuracy: 0.5455 - val_loss: 0.6989 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6795 - accuracy: 0.5909 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6762 - accuracy: 0.5909 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6757 - accuracy: 0.5909 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6747 - accuracy: 0.5909 - val_loss: 0.7047 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6730 - accuracy: 0.5909 - val_loss: 0.6967 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6818 - accuracy: 0.5909 - val_loss: 0.6848 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6751 - accuracy: 0.5909 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6797 - accuracy: 0.5909 - val_loss: 0.6988 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6814 - accuracy: 0.5909 - val_loss: 0.6993 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6842 - accuracy: 0.5909 - val_loss: 0.7040 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6812 - accuracy: 0.5909 - val_loss: 0.7006 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6818 - accuracy: 0.5909 - val_loss: 0.7028 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6786 - accuracy: 0.5909 - val_loss: 0.7008 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6792 - accuracy: 0.5909 - val_loss: 0.7002 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6786 - accuracy: 0.5909 - val_loss: 0.6994 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6787 - accuracy: 0.5909 - val_loss: 0.7027 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6775 - accuracy: 0.5909 - val_loss: 0.7031 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6776 - accuracy: 0.5909 - val_loss: 0.7035 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6773 - accuracy: 0.5909 - val_loss: 0.6996 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6776 - accuracy: 0.5909 - val_loss: 0.6974 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6785 - accuracy: 0.5909 - val_loss: 0.7015 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6794 - accuracy: 0.5909 - val_loss: 0.7042 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6803 - accuracy: 0.5909 - val_loss: 0.7024 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6780 - accuracy: 0.5909 - val_loss: 0.7024 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6776 - accuracy: 0.5909 - val_loss: 0.7078 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6777 - accuracy: 0.5909 - val_loss: 0.7029 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6773 - accuracy: 0.5909 - val_loss: 0.7032 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6774 - accuracy: 0.5909 - val_loss: 0.7026 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6772 - accuracy: 0.5909 - val_loss: 0.7068 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6784 - accuracy: 0.5909 - val_loss: 0.7071 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6767 - accuracy: 0.5909 - val_loss: 0.7073 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7059 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6775 - accuracy: 0.5909 - val_loss: 0.7062 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6776 - accuracy: 0.5909 - val_loss: 0.7055 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6769 - accuracy: 0.5909 - val_loss: 0.7059 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6768 - accuracy: 0.5909 - val_loss: 0.7077 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7068 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6767 - accuracy: 0.5909 - val_loss: 0.7072 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7077 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7081 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7081 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7082 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7083 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7085 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7086 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7087 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7104 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7106 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6760 - accuracy: 0.5909 - val_loss: 0.7123 - val_accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7118 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6768 - accuracy: 0.5909 - val_loss: 0.7096 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6769 - accuracy: 0.5909 - val_loss: 0.7115 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7116 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7116 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7117 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7117 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7116 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7116 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7115 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7114 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7096 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7113 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7096 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7100 - val_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6770 - accuracy: 0.5909 - val_loss: 0.7109 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7107 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7106 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7104 - val_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7103 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7101 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7100 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7099 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7098 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7097 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7096 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7095 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6764 - accuracy: 0.5909 - val_loss: 0.7099 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7099 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7093 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7092 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7091 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6763 - accuracy: 0.5909 - val_loss: 0.7090 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7089 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6764 - accuracy: 0.5909 - val_loss: 0.7089 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6764 - accuracy: 0.5909 - val_loss: 0.7088 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6764 - accuracy: 0.5909 - val_loss: 0.7087 - val_accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7087 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7087 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7087 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6766 - accuracy: 0.5909 - val_loss: 0.7087 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7088 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7088 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - accuracy: 0.5909 - val_loss: 0.7089 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13e4da2efd0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.compile(loss=loss, optimizer=optim, metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=100, validation_data=(X_test, y_test))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=5, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = txt_pre_process('base(wrong_execution).txt',0)\n",
    "wrong_inputs = padding(wrong[0])\n",
    "wrong_label = wrong[1]\n",
    "\n",
    "\n",
    "correct = txt_pre_process('base(correct_execution).txt',1)\n",
    "correct_inputs = padding(wrong[0])\n",
    "correct_label = wrong[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wrong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m ctr_0\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m      2\u001b[0m ctr_1\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m inputss \u001b[39m=\u001b[39m wrong\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(inputss[\u001b[39m0\u001b[39m])):\n\u001b[0;32m      5\u001b[0m     input_sequence \u001b[39m=\u001b[39m inputss[\u001b[39m0\u001b[39m][x]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wrong' is not defined"
     ]
    }
   ],
   "source": [
    "ctr_0=0\n",
    "ctr_1=0\n",
    "inputss = wrong\n",
    "for x in range(len(inputss[0])):\n",
    "    input_sequence = inputss[0][x]\n",
    "    length_input = max_length - len(input_sequence)\n",
    "    if length_input>=0:\n",
    "        padded_input = np.pad(input_sequence, ((0, max_length - len(input_sequence)), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        padded_input = input_sequence[:max_length]\n",
    "\n",
    "    reshaped_input = np.reshape(padded_input, (1, max_length, 66))\n",
    "\n",
    "\n",
    "    # print(reshaped_input.shape )\n",
    "\n",
    "    logits = model.predict(reshaped_input )\n",
    "\n",
    "    threshold = 0.8\n",
    "    binary_predictions = (logits > threshold).astype(int)\n",
    "\n",
    "    print(\"Predicted logits:\", logits)\n",
    "    print(\"Binary predictions:\", binary_predictions[0][0])\n",
    "    if binary_predictions[0][0] == 1:\n",
    "        ctr_1 = ctr_1 + 1\n",
    "    else:\n",
    "        ctr_0 = ctr_0 + 1\n",
    "\n",
    "print('ctr_1 ->',ctr_1)\n",
    "print('ctr_0 ->',ctr_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image,results):\n",
    "    # mp_drawing.draw_landmarks(image,results.face_landmarks,mp_holistic.FACEMESH_TESSELATION)\n",
    "    mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image,model):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image,results):\n",
    "    mp_drawing.draw_landmarks(image,results.face_landmarks,mp_holistic.FACEMESH_TESSELATION,\n",
    "                              mp_drawing.DrawingSpec(color=(80,110,10), thickness = 1, circle_radius = 1),\n",
    "                              mp_drawing.DrawingSpec(color=(80,256,121), thickness = 1, circle_radius = 1))\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(80,110,10), thickness = 1, circle_radius = 4),\n",
    "                              mp_drawing.DrawingSpec(color=(80,256,121), thickness = 1, circle_radius = 2))\n",
    "\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(80,110,10), thickness = 1, circle_radius = 4),\n",
    "                              mp_drawing.DrawingSpec(color=(80,256,121), thickness = 1, circle_radius = 2))\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(80,110,10), thickness = 1, circle_radius = 4),\n",
    "                              mp_drawing.DrawingSpec(color=(80,256,121), thickness = 1, circle_radius = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image, results = mediapipe_detection(frame,holistic)\n",
    "\n",
    "        draw_styled_landmarks(image,results)\n",
    "\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        if cv2.waitKey(10) & 0xff == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(results.right_hand_landmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_compile_landmarks = []\n",
    "temp_compile_landmarks_lh = []\n",
    "temp_compile_landmarks_rh = []\n",
    "\n",
    "# for coor in results.pose_landmarks.landmark:\n",
    "#      temp = np.array([coor.x,coor.y,coor.z,coor.visibility])\n",
    "#      temp_compile_landmarks.append(temp)\n",
    "def data_extractions(results):\n",
    "    temp_compile_landmarks = np.array([[coor.x,coor.y,coor.z,coor.visibility] for res in results.pose_landmarks.landmark] if results.left_hand_landmarks else np.zeros(132) ).flatten() \n",
    "    # temp_compile_landmarks_lh = np.array([[coor.x,coor.y,coor.z,coor.visibility] for res in results.left_hand_landmarks.landmark] if results.left_hand_landmarks else np.zeros(21*3)).flatten()\n",
    "    # temp_compile_landmarks_rh = np.array([[coor.x,coor.y,coor.z,coor.visibility] for res in results.right_hand_landmarks.landmark] if results.right_hand_landmarks else np.zeros(21*3)).flatten()\n",
    "    return temp_compile_landmarks\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
